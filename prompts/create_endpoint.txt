Add an endpoint to create a new project. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects` that reveives a `{"name": "Project name"}` JSON. The owner will be the currently logged in user. The training dataset and finetune are empty. The status is `ACTIVE`.

---

Add an endpoint to create a new initial training dateset for a project. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects/{project_id}/training-datasets` that reveives the following JSON (the values are examples):

{
    "corpus_name": "eurlex",
    "input_field": "question",
    "output_field": "answer",
    "language_iso": "deu",
    "field_names": ["question", "answer", "complexity"],
    "generate_prompt": "You task is to generate training dataset for question answering."
}

The status is `PLANNING`. The prompt history is empty.

---

Add an endpoint to update the status of a training dataset. The endpoint will be available at `/api/external/training-datasets/{training_dataset_id}/update-status` and will be only accessible via a given API key. Create a new protected API group for `/api/external`, we will add more endpoints later. The API key is available in the environment variable `APP_EXTERNAL_API_KEY`. The allowed status to set via this endpoint are `RUNNING`, `FAILED` and `DONE`.

---

Add an endpoint that returns a training dataset with its metadata and the first 10 training data items. THe endpoint will be available at `/api/projects/{project_id}/training-datasets/{training_dataset_id}`. We need the the following fields from the metadata:

- version
- generate_prompt
- input_field
- output_field
- generate_examples_number
- corpus_name
- language_iso
- status
- field_names
- data_items_sample

If the status is not `DONE` then the data_items_sample will be an empty list, otherwise it will contain the first 10 data items that are not deleted and where there is no other data item that `corrects` them. Each data item in the sample will be just a list of its `values`, we will not need the other fields.

---

Add an endpoint to create a new finetune. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects/{project_id}/finetunes` that reveives the following JSON (the values are examples):

{
    "base_model_name": "qwen3b:4b",
    "training_dataset_id": "{training_dataset_id}",
    "training_dataset_nubmer_example: 1000,
    "training_dataset_select_random: false
}

The status is `PLANNING`. The `model_name` we will create from `{base_model_name}_{project_name_model_string}_v{version}`. The project name model string consists of the small letter model name (alphanumeric character only), empty spaces replaced by underscore.

---

Add an endpoint to update the status of a finetune. The endpoint will be available at `/api/external/finetunes/{finetune_id}/update-status` and will be only accessible via a given API key. Add it to the protected API group for `/api/external`. The API key is available in the environment variable `APP_EXTERNAL_API_KEY`. The allowed status to set via this endpoint are `RUNNING`, `FAILED` and `DONE`. Implement this endpoint in the same way that `/api/external/training-datasets/{training_dataset_id}/update-status`, just for now we do not run any specific code in the use case when the status is set to `DONE`.

---

Add an endpoint that returns a finetune with its metadata. The endpoint will be available at `/api/projects/{project_id}/finetunes/{finetune_id}`. We need the the following fields from the metadata:

- version
- status
- base_model_name
- training_dataset_id
- training_dataset_nubmer_example
- training_dataset_select_random
- model_size_gb
- model_size_parameter
- model_dtype
- model_quantization
- inference_samples
- training_time_seconds
