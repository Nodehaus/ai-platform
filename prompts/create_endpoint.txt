Add an endpoint to create a new project. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects` that reveives a `{"name": "Project name"}` JSON. The owner will be the currently logged in user. The training dataset and finetune are empty. The status is `ACTIVE`.

---

Add an endpoint to create a new initial training dateset for a project. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects/{project_id}/training-datasets` that reveives the following JSON (the values are examples):

{
    "corpus_name": "eurlex",
    "input_field": "question",
    "output_field": "answer",
    "language_iso": "deu",
    "field_names": ["question", "answer", "complexity"],
    "generate_prompt": "You task is to generate training dataset for question answering."
}

The status is `PLANNING`. The prompt history is empty.

---

Add an endpoint to update the status of a training dataset. The endpoint will be available at `/api/external/training-datasets/{training_dataset_id}/update-status` and will be only accessible via a given API key. Create a new protected API group for `/api/external`, we will add more endpoints later. The API key is available in the environment variable `APP_EXTERNAL_API_KEY`. The allowed status to set via this endpoint are `RUNNING`, `FAILED` and `DONE`.

---

Add an endpoint that returns a training dataset with its metadata and the first 10 training data items. THe endpoint will be available at `/api/projects/{project_id}/training-datasets/{training_dataset_id}`. We need the the following fields from the metadata:

- version
- generate_prompt
- input_field
- output_field
- generate_examples_number
- corpus_name
- language_iso
- status
- field_names
- data_items_sample

If the status is not `DONE` then the data_items_sample will be an empty list, otherwise it will contain the first 10 data items that are not deleted and where there is no other data item that `corrects` them. Each data item in the sample will be just a list of its `values`, we will not need the other fields.

---

Add an endpoint to create a new finetune. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects/{project_id}/finetunes` that reveives the following JSON (the values are examples):

{
    "base_model_name": "qwen3b:4b",
    "training_dataset_id": "{training_dataset_id}",
    "training_dataset_nubmer_example: 1000,
    "training_dataset_select_random: false
}

The status is `PLANNING`. The `model_name` we will create from `{base_model_name}_{project_name_model_string}_v{version}`. The project name model string consists of the small letter model name (alphanumeric character only), empty spaces replaced by underscore.

---

Add an endpoint to update the status of a finetune. The endpoint will be available at `/api/external/finetunes/{finetune_id}/update-status` and will be only accessible via a given API key. Add it to the protected API group for `/api/external`. The API key is available in the environment variable `APP_EXTERNAL_API_KEY`. The allowed status to set via this endpoint are `RUNNING`, `FAILED` and `DONE`. Implement this endpoint in the same way that `/api/external/training-datasets/{training_dataset_id}/update-status`, just for now we do not run any specific code in the use case when the status is set to `DONE`.

---

Add an endpoint that returns a finetune with its metadata. The endpoint will be available at `/api/projects/{project_id}/finetunes/{finetune_id}`. We need the the following fields from the metadata:

- version
- status
- base_model_name
- training_dataset_id
- training_dataset_nubmer_example
- training_dataset_select_random
- model_size_gb
- model_size_parameter
- model_dtype
- model_quantization
- inference_samples
- training_time_seconds

---

Add an endpoint that allows a user to download a finetune model. The endpoint will be available at `/api/projects/{project_id}/finetunes/{finetune_id}/download`. The models are on S3 in a folder as single files `/finetunes/{finetune_id}/{model_name}.gguf`. You need to implement a new `DownloadModelClient` to get the file from S3 and then forward it to the API endpoint. The files might be large, find a memory efficient solution for streaming.

---

Add an endpoint that allows users to download a training dataset. The endpoint will be available at `/api/projects/{project_id}/training-datasets/{training_dataset_id}/download`. The download will be CSV file that contains all data items of the training dataset. The CVS has a header with the `field_names`. The goal is that users can open the CSV files in Excel or Google Sheets.

---

And an endpoint to analyze a prompt that the user entered to create a training dataset. The endpoint will be avaible at `/api/analyze-training-dataset-prompt`. It will accept one prompt as a string and return the folowing:

```
- analysis_result (string, text about how to improve the prompt)
- json_object_fields (string, a JSON object with field names and descriptions)
- input_field (string)
- output_field (string)
- expected_output_size_chars (int)
```

For the values the use case will make two calls to the LLM with the OllamaLLMClient with specific prompts. The first ask the LLM for the `analysis_result`. The second will have the following prompt:

```
Tell me what list of JSON objects an LLM would output for a given prompt. \
It does not need to output any source text or reference, **ignore** any mentions of source text. \
Include minimum 2 fields, maximum 4 fields. We want to use the output data for LLM training. \
Decide which fields we will use as input and output of the training. \
Also return the expected size of the output in characters based on your output field description. \
Use the following output format:

```json
{
  "json_object_fields": {
    "field_name": "Description of what this field represents",
    "another_field": "Description of this field",
    "yet_another_field": "More descriptions"
  },
  "input_field": "field_name",
  "output_field": "another_field",
  "expected_output_size_chars": a_reasonable_int_for_output_size
}
```

PROMPT:

[Prompt from endpoint command]

JSON:
```

Add a service with two functions and their prompts for those LLM calls.

---

Add an endpoint `/projects/:project_id/finetunes/:finetune_id/completion` that accepts a JSON with a prompt and returns an LLM completion string. We can use the existing OllamaLLMClient to generate the completion. As a model you need to pass the `model_name` of the finetune.

---

Add an endpoint to create a new deployment. You can find information about the database models in `plans/database_models.md`. For now we only want one more POST endpoint `/api/projects/{project_id}/deployments` that reveives the following JSON (the values are examples):

{
    "model_name": "some_model_name",
    "finetune_id": "optional_finetune_id"
}

When creating a deployment then also create a new API key for the database entry.

---

Add two OpenAI compatible endpoints at `/public/{project_id}/completions` and `/public/{project_id}/chat/completions`. Create a new route group for those that will check the API key based on the model name that we can find in the deployments. Use the OllamaLLMClient to forward the request.

```

Add an endpoint `/projects/:project_id/deployments/:deployment_id/logs_download` that returns the logs of the deployment as CSV file. It must return all log entries with three columns: date, input, output. We have a similar endpoint at `/projects/:project_id/training-datasets/:training_dataset_id/download` that returns the training dataset as CSV.