We want to implement an S3 client to submit the training dataset creation job as a JSON to S3. Implement an adapter `training_dataset_job_client.go` that writes the following JSON to a S3 bucket (the values are examples):

```
{
    "corpus_s3_path": "/documents/eurlex",
    "corpus_files_subset": [],
    "language_iso": "deu",
    "user_id": "72b45c20-874e-4e2a-871c-519de0b0d5eb",
    "training_dataset_id": "9c29d344-bade-4e98-ae0b-910841068790",
    "generate_prompt": "You task is to generate training dataset for question answering.",
    "generate_examples_number": 100
    "generate_model": "gemma3:8b",
    "generate_model_runner": "runpod_ollama"
}
```

We will configure the S3 client with three environment variables, you can assume they exist: AWS_ENDPOINT_URL, AWS_DEFAULT_REGION and APP_S3_BUCKET. The path for the job files is `/jobs`.

The job file will be written in the use case after we created the training dataset in the database.

---

We want to implement another S3 client to get all training dataset JSONs that an external runner generated. The client will get all the JSON files from the path `datasets/{training_dataset_id}/`. Each JSON file contains two fields that we need: `total_generation_time_seconds` and `annotations`. You can find an example JSON file in `02002L0058-20091219_eng.json`. Sum up all `total_generation_time_seconds` to get the number for the full training dataset generation. Return all annotations in a single list. We want to use that client in the `internal/application/domain/use_cases/update_training_dataset_status_use_case_impl.go`. When the status is set to `DONE` we will get all the annotations and the `total_generation_time_seconds` and write it to the database as TrainingDataItem. Check that each annotation has the fields defined in `FieldNames` and write them in the same order to the `values` of the `TrainingDataItem`. The field `question`, `answer` and `complexity` are specific to this one training dataset. Other datasets might have different fields, depending on the `FieldNames`.

---

We want to implement an S3 client to submit the finetune training job as JSON to S3. The job file need to contain the all or a random selection of TrainingDataItems of a TrainingDataset. Implement an adapter `finetune_job_client.go that writes the following JSON (the values are examples):

```
{
    "training_dataset_id": "9c29d344-bade-4e98-ae0b-910841068790",
    "input_field": "question",
    "output_field": "answer",
    "training_data":[
        {
            "field1": "value1",
            "field2": "value2",
        },
        {
            [... next item ...]
        },
        [... next items ...]
    ]
}

If input field is the string "source_text" we need three more fields in each data item: `source_document`, `source_document_start` and `source_document_end`.

Implement also, in the training dataset service, a subset selection of the data items with parameters TrainingDatasetNumberExamples and TrainingDatasetSelectRandom (whether to select random or in order). We will use this selection if we get the info that the user wants a finetune with less data items than exist in the training dataset.

We will configure the S3 client with three environment variables, you can assume they exist: AWS_ENDPOINT_URL, AWS_DEFAULT_REGION and APP_S3_BUCKET. The path for the job files is `/jobs/finetunes`.

The job file will be written in the create finetune use case after we created the finetune in the database.

---

We now need a client that start the finetune training job on Runpod. Send the following JSON with information about the finetune to the runpod API (the values are examples):

{
    "s3_bucket": "nodehaus",
    "training_dataset_s3_path": "jobs/finetunes/250927101726_cb1b846e-ab09-417e-823c-475107bda72a.json",
    "documents_s3_path": "documents/eurlex/eng",
    "base_model_name": "qwen3:4b",
    "model_name": "qwen3b_4b_test_radio_buttons_v11"
}

There are two environment variables `RUNPOD_API_KEY` and `RUNPOD_POD_ID` to access the Runpod API.

We will call the API after the JSON job file has been written in the create finetune use case.

---

Implement a client to call an LLM inference endpoint on Runpod. The endpoint accepts the following payload:

```
{
    "input": {
        "openai_route": "/v1/completions",
        "openai_input": {
            "model": model,
            "prompt": prompt,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
        },
    }
}
```

The model is `qwen3:30b-a3b-instruct-2507-q4_K_M`, the rest are parameters for the client. Return just the response string from the LLM. The runpod ID is in the environment variable `RUNPOD_POD_ID_OLLAMA`, the runpod API key is in `RUNPOD_API_KEY`.